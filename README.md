------------------------------------------------------------------------------------------------------
ATELIER PRA/PCA
------------------------------------------------------------------------------------------------------
Lâ€™idÃ©e en 30 secondes : Cet atelier met en Å“uvre un **mini-PRA** sur **Kubernetes** en dÃ©ployant une **application Flask** avec une **base SQLite** stockÃ©e sur un **volume persistant (PVC pra-data)** et des **sauvegardes automatiques rÃ©alisÃ©es chaque minute vers un second volume (PVC pra-backup)** via un **CronJob**. Lâ€™**image applicative est construite avec Packer** et le **dÃ©ploiement orchestrÃ© avec Ansible**, tandis que Kubernetes assure la gestion des pods et de la disponibilitÃ© applicative. Nous observerons la diffÃ©rence entre **disponibilitÃ©** (recrÃ©ation automatique des pods sans perte de donnÃ©es) et **reprise aprÃ¨s sinistre** (perte volontaire du volume de donnÃ©es puis restauration depuis les backups), nous mesurerons concrÃ¨tement les RTO et RPO, et comprendrons les limites dâ€™un PRA local non rÃ©pliquÃ©. Cet atelier illustre de maniÃ¨re pratique les principes de continuitÃ© et de reprise dâ€™activitÃ©, ainsi que le rÃ´le respectif des conteneurs, du stockage persistant et des mÃ©canismes de sauvegarde.
  
**Architecture cible :** Ci-dessous, voici l'architecture cible souhaitÃ©e.   
  
![Screenshot Actions](Architecture_cible.png)  
  
-------------------------------------------------------------------------------------------------------
SÃ©quence 1 : Codespace de Github
-------------------------------------------------------------------------------------------------------
Objectif : CrÃ©ation d'un Codespace Github  
DifficultÃ© : TrÃ¨s facile (~5 minutes)
-------------------------------------------------------------------------------------------------------
**Faites un Fork de ce projet**. Si besoin, voici une vidÃ©o d'accompagnement pour vous aider Ã  "Forker" un Repository Github : [Forker ce projet](https://youtu.be/p33-7XQ29zQ) 
  
Ensuite depuis l'onglet **[CODE]** de votre nouveau Repository, **ouvrez un Codespace Github**.
  
---------------------------------------------------
SÃ©quence 2 : CrÃ©ation du votre environnement de travail
---------------------------------------------------
Objectif : CrÃ©er votre environnement de travail  
DifficultÃ© : Simple (~10 minutes)
---------------------------------------------------
Vous allez dans cette sÃ©quence mettre en place un cluster Kubernetes K3d contenant un master et 2 workers, installer les logiciels Packer et Ansible. Depuis le terminal de votre Codespace copier/coller les codes ci-dessous Ã©tape par Ã©tape :  

**CrÃ©ation du cluster K3d**  
```
curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash
```
```
k3d cluster create pra \
  --servers 1 \
  --agents 2
```
**vÃ©rification de la crÃ©ation de votre cluster Kubernetes**  
```
kubectl get nodes
```
**Installation du logiciel Packer (crÃ©ation d'images Docker)**  
```
PACKER_VERSION=1.11.2
curl -fsSL -o /tmp/packer.zip \
  "https://releases.hashicorp.com/packer/${PACKER_VERSION}/packer_${PACKER_VERSION}_linux_amd64.zip"
sudo unzip -o /tmp/packer.zip -d /usr/local/bin
rm -f /tmp/packer.zip
```
**Installation du logiciel Ansible**  
```
python3 -m pip install --user ansible kubernetes PyYAML jinja2
export PATH="$HOME/.local/bin:$PATH"
ansible-galaxy collection install kubernetes.core
```
  
---------------------------------------------------
SÃ©quence 3 : DÃ©ploiement de l'infrastructure
---------------------------------------------------
Objectif : DÃ©ployer l'infrastructure sur le cluster Kubernetes
DifficultÃ© : Facile (~15 minutes)
---------------------------------------------------  
Nous allons Ã  prÃ©sent dÃ©ployer notre infrastructure sur Kubernetes. C'est Ã  dire, crÃ©Ã©r l'image Docker de notre application Flask avec Packer, dÃ©poser l'image dans le cluster Kubernetes et enfin dÃ©ployer l'infratructure avec Ansible (CrÃ©ation du pod, crÃ©ation des PVC et les scripts des sauvegardes aututomatiques).  

**CrÃ©ation de l'image Docker avec Packer**  
```
packer init .
packer build -var "image_tag=1.0" .
docker images | head
```
  
**Import de l'image Docker dans le cluster Kubernetes**  
```
k3d image import pra/flask-sqlite:1.0 -c pra
```
  
**DÃ©ploiment de l'infrastructure dans Kubernetes**  
```
ansible-playbook ansible/playbook.yml
```
  
**Forward du port 8080 qui est le port d'exposition de votre application Flask**  
```
kubectl -n pra port-forward svc/flask 8080:80 >/tmp/web.log 2>&1 &
```
  
---------------------------------------------------  
**RÃ©ccupÃ©ration de l'URL de votre application Flask**. Votre application Flask est dÃ©ployÃ©e sur le cluster K3d. Pour obtenir votre URL cliquez sur l'onglet **[PORTS]** dans votre Codespace (Ã  cotÃ© de Terminal) et rendez public votre port 8080 (VisibilitÃ© du port). Ouvrez l'URL dans votre navigateur et c'est terminÃ©.  

**Les routes** Ã  votre disposition sont les suivantes :  
1. https://...**/** affichera dans votre navigateur "Bonjour tout le monde !".
2. https://...**/health** pour voir l'Ã©tat de santÃ© de votre application.
3. https://...**/add?message=test** pour ajouter un message dans votre base de donnÃ©es SQLite.
4. https://...**/count** pour afficher le nombre de messages stockÃ©s dans votre base de donnÃ©es SQLite.
5. https://...**/consultation** pour afficher les messages stockÃ©s dans votre base de donnÃ©es.
  
---------------------------------------------------  
### Processus de sauvegarde de la BDD SQLite

GrÃ¢ce Ã  une tÃ¢che CRON dÃ©ployÃ©e par Ansible sur le cluster Kubernetes (un CronJob), toutes les minutes une sauvegarde de la BDD SQLite est faite depuis le PVC pra-data vers le PCV pra-backup dans Kubernetes.  

Pour visualiser les sauvegardes pÃ©riodiques dÃ©posÃ©es dans le PVC pra-backup, coller les commandes suivantes dans votre terminal Codespace :  

```
kubectl -n pra run debug-backup \
  --rm -it \
  --image=alpine \
  --overrides='
{
  "spec": {
    "containers": [{
      "name": "debug",
      "image": "alpine",
      "command": ["sh"],
      "stdin": true,
      "tty": true,
      "volumeMounts": [{
        "name": "backup",
        "mountPath": "/backup"
      }]
    }],
    "volumes": [{
      "name": "backup",
      "persistentVolumeClaim": {
        "claimName": "pra-backup"
      }
    }]
  }
}'
```
```
ls -lh /backup
```
**Pour sortir du cluster et revenir dans le terminal**
```
exit
```

---------------------------------------------------
SÃ©quence 4 : ğŸ’¥ ScÃ©narios de crash possibles  
DifficultÃ© : Facile (~30 minutes)
---------------------------------------------------
### ğŸ¬ **ScÃ©nario 1 : PCA â€” Crash du pod**  
Nous allons dans ce scÃ©nario **dÃ©truire notre Pod Kubernetes**. Ceci simulera par exemple la supression d'un pod accidentellement, ou un pod qui crash, ou un pod redÃ©marrÃ©, etc..

**Destruction du pod :** Ci-dessous, la cible de notre scÃ©nario   
  
![Screenshot Actions](scenario1.png)  

Nous perdons donc ici notre application mais pas notre base de donnÃ©es puisque celle-ci est dÃ©posÃ©e dans le PVC pra-data hors du pod.  

Copier/coller le code suivant dans votre terminal Codespace pour dÃ©truire votre pod :
```
kubectl -n pra get pods
```
Notez le nom de votre pod qui est diffÃ©rent pour tout le monde.  
Supprimez votre pod (pensez Ã  remplacer <nom-du-pod-flask> par le nom de votre pod).  
Exemple : kubectl -n pra delete pod flask-7c4fd76955-abcde  
```
kubectl -n pra delete pod <nom-du-pod-flask>
```
**VÃ©rification de la suppression de votre pod**
```
kubectl -n pra get pods
```
ğŸ‘‰ **Le pod a Ã©tÃ© reconstruit sous un autre identifiant**.  
Forward du port 8080 du nouveau service  
```
kubectl -n pra port-forward svc/flask 8080:80 >/tmp/web.log 2>&1 &
```
Observez le rÃ©sultat en ligne  
https://...**/consultation** -> Vous n'avez perdu aucun message.
  
ğŸ‘‰ Kubernetes gÃ¨re tout seul : Aucun impact sur les donnÃ©es ou sur votre service (PVC conserve la DB et le pod est reconstruit automatiquement) -> **C'est du PCA**. Tout est automatique et il n'y a aucune rupture de service.
  
---------------------------------------------------
### ğŸ¬ **ScÃ©nario 2 : PRA - Perte du PVC pra-data** 
Nous allons dans ce scÃ©nario **dÃ©truire notre PVC pra-data**. C'est Ã  dire nous allons suprimer la base de donnÃ©es en production. Ceci simulera par exemple la corruption de la BDD SQLite, le disque du node perdu, une erreur humaine, etc. ğŸ’¥ Impact : IL s'agit ici d'un impact important puisque **la BDD est perdue**.  

**Destruction du PVC pra-data :** Ci-dessous, la cible de notre scÃ©nario   
  
![Screenshot Actions](scenario2.png)  

ğŸ”¥ **PHASE 1 â€” Simuler le sinistre (perte de la BDD de production)**  
Copier/coller le code suivant dans votre terminal Codespace pour dÃ©truire votre base de donnÃ©es :
```
kubectl -n pra scale deployment flask --replicas=0
```
```
kubectl -n pra patch cronjob sqlite-backup -p '{"spec":{"suspend":true}}'
```
```
kubectl -n pra delete job --all
```
```
kubectl -n pra delete pvc pra-data
```
ğŸ‘‰ Vous pouvez vÃ©rifier votre application en ligne, la base de donnÃ©es est dÃ©truite et la service n'est plus accÃ©ssible.  

âœ… **PHASE 2 â€” ProcÃ©dure de restauration**  
RecrÃ©er lâ€™infrastructure avec un PVC pra-data vide.  
```
kubectl apply -f k8s/
```
VÃ©rification de votre application en ligne.  
Forward du port 8080 du service pour tester l'application en ligne.  
```
kubectl -n pra port-forward svc/flask 8080:80 >/tmp/web.log 2>&1 &
```
https://...**/count** -> =0.  
https://...**/consultation** Vous avez perdu tous vos messages.  

Retaurez votre BDD depuis le PVC Backup.  
```
kubectl apply -f pra/50-job-restore.yaml
```
ğŸ‘‰ Vous pouvez vÃ©rifier votre application en ligne, **votre base de donnÃ©es a Ã©tÃ© restaureÃ©** et tous vos messages sont bien prÃ©sents.  

Relance des CRON de sauvgardes.  
```
kubectl -n pra patch cronjob sqlite-backup -p '{"spec":{"suspend":false}}'
```
ğŸ‘‰ Nous n'avons pas perdu de donnÃ©es mais Kubernetes ne gÃ¨re pas la restauration tout seul. Nous avons du protÃ©ger nos donnÃ©es via des sauvegardes rÃ©guliÃ¨res (du PVC pra-data vers le PVC pra-backup). -> **C'est du PRA**. Il s'agit d'une stratÃ©gie de sauvegarde avec une procÃ©dure de restauration.  

---------------------------------------------------
SÃ©quence 5 : Exercices  
DifficultÃ© : Moyenne (~45 minutes)
---------------------------------------------------
**ComplÃ©tez et documentez ce fichier README.md** pour rÃ©pondre aux questions des exercices.  
Faites preuve de pÃ©dagogie et soyez clair dans vos explications et procedures de travail.  

**Exercice 1 :**  
Quels sont les composants dont la perte entraÃ®ne une perte de donnÃ©es ?  
  
**RÃ©ponse :**  
Dans cette architecture, **seul le PVC pra-data** est un point critique dont la perte entraÃ®ne une perte de donnÃ©es irrÃ©versible (Ã  moins de disposer d'un backup) :

- **PVC pra-data** : **CRITIQUE** â€” Contient la base de donnÃ©es SQLite. Sa destruction entraÃ®ne la perte immÃ©diate de toutes les donnÃ©es.
- **Pod Flask** : Non critique â€” En cas de suppression, Kubernetes le recrÃ©e automatiquement grÃ¢ce au Deployment.yml. Les donnÃ©es sont prÃ©servÃ©es car elles sont sur le PVC (stockage persistant).
- **PVC pra-backup** : Non critique pour les donnÃ©es courantes, mais **ESSENTIEL pour le PRA** â€” Contient les sauvegardes. Sa perte compromet la stratÃ©gie de reprise.
- **CronJob** : Non critique â€” En cas de suppression, il peut Ãªtre restaurÃ© depuis les manifests Kubernetes.

**Conclusion :** Le stockage persistant (PVC) est le seul composant dont la perte provoque une perte de donnÃ©es. C'est pourquoi les stratÃ©gies de sauvegarde doivent protÃ©ger ce composant critique.

**Exercice 2 :**  
Expliquez nous pourquoi nous n'avons pas perdu les donnÃ©es lors de la supression du PVC pra-data  
  
**RÃ©ponse :**  
Bien que nous ayons supprimÃ© le PVC pra-data (et donc physiquement dÃ©truit la base de donnÃ©es), nous n'avons pas perdu les donnÃ©es pour une raison simple : **nous disposions de sauvegardes rÃ©guliÃ¨res dans le PVC pra-backup**.

**MÃ©canisme de sauvegarde :**
- Un CronJob exÃ©cute une sauvegarde **toutes les minutes**
- Cette tÃ¢che copie la base de donnÃ©es SQLite du PVC pra-data vers le PVC pra-backup
- Le PVC pra-backup se trouve sur le mÃªme cluster, protÃ©geant ainsi les donnÃ©es contre la perte du volume primaire

**Processus de rÃ©cupÃ©ration :**
1. Suppression accidentelle du PVC pra-data â†’ DonnÃ©es perdues du volume primaire
2. RecrÃ©ation d'un nouveau PVC pra-data vide (via `kubectl apply -f k8s/`) â†’ Service revient en ligne mais compte des messages = 0
3. ExÃ©cution du job de restauration (`kubectl apply -f pra/50-job-restore.yaml`) â†’ Copie du backup depuis pra-backup vers le nouveau pra-data
4. Les donnÃ©es sont restaurÃ©es avec un maximum 1 minute de perte (l'intervalle entre deux sauvegardes)

**Apprentissage clÃ© :** Sans sauvegarde, cette opÃ©ration aurait entraÃ®nÃ© une perte dÃ©finitive des donnÃ©es. Les sauvegardes rÃ©guliÃ¨res sont la clÃ© du PRA.

**Exercice 3 :**  
Quels sont le RTO et RPO de cette solution ?  
  
**RÃ©ponse :**  

**RPO (Recovery Point Objective) = 1 minute**
- Definition : QuantitÃ© maximum de donnÃ©es que vous Ãªtes prÃªt Ã  perdre en cas de sinistre
- Dans cette solution : Les sauvegardes s'exÃ©cutent **toutes les minutes**
- Conclusion : En cas de sinistre, vous risquez de perdre au maximum **1 minute de donnÃ©es** (les Ã©vÃ©nements saisis aprÃ¨s la derniÃ¨re sauvegarde)
- Exemple : Si la derniÃ¨re sauvegarde a eu lieu Ã  14h30:00 et le sinistre Ã  14h30:45, vous perdez 45 secondes de donnÃ©es

**RTO (Recovery Time Objective) = 5 Ã  10 minutes**
- Definition : Temps maximal acceptable pour restaurer le service aprÃ¨s un sinistre
- Dans cette solution :
  - Suppression du cluster / dÃ©tection du sinistre : ~1 minute
  - RecrÃ©ation du PVC pra-data et du pod : ~2-3 minutes
  - ExÃ©cution du job de restauration (copie du backup) : ~2-5 minutes (dÃ©pend de la taille des donnÃ©es)
  - Tests de fonctionnalitÃ© : ~1 minute
- Conclusion : Le service est restaurÃ© en **5 Ã  10 minutes** en fonction de la taille des donnÃ©es

**Exercice 4 :**  
Pourquoi cette solution (cet atelier) ne peux pas Ãªtre utilisÃ©e dans un vrai environnement de production ? Que manque-t-il ?   
  
**RÃ©ponse :**  
Bien que cette solution dÃ©montre les principes du PRA, elle prÃ©sente **plusieurs limitations critiques** pour un environnement de production :

**1. Pas de rÃ©plication gÃ©ographique**
- **ProblÃ¨me** : Tous les Ã©lÃ©ments (application, donnÃ©es, backups) sont sur le **mÃªme cluster physique**
- **Risque** : Une catastrophe affectant le datacenter entier (incendie, panne Ã©lectrique, tremblement de terre) dÃ©truit application ET backups
- **Solution production** : RÃ©pliquer les donnÃ©es et backups sur une **rÃ©gion gÃ©ographique distante**

**2. Backups localisÃ©s sur le mÃªme cluster**
- **ProblÃ¨me** : Les sauvegardes (PVC pra-backup) et les donnÃ©es (PVC pra-data) rÃ©sident sur le **mÃªme systÃ¨me de stockage**
- **Risque** : Corruption, panne ou attaque affectant l'infrastructure locale dÃ©truit donnÃ©es ET backups
- **Solution production** : Exporter les backups vers un **stockage externe** (S3 par exemple) pour garantir leur indÃ©pendance

**3. Pas de chiffrement des donnÃ©es**
- **ProblÃ¨me** : Les donnÃ©es et backups circulent et sont stockÃ©s en clair
- **Risque** : AccÃ¨s non autorisÃ©, vol de donnÃ©es, non-conformitÃ© rÃ©glementaire (RGPD, PCI-DSS)
- **Solution production** : Chiffrer les donnÃ©es **en transit** (TLS) et **au repos** (AES-256)

**4. Pas de monitoring ni d'alerting**
- **ProblÃ¨me** : Aucune visibilitÃ© sur l'Ã©tat des sauvegardes ou la santÃ© de l'infrastructure
- **Risque** : Un backup qui Ã©choue silencieusement dÃ©couvert trop tard (au moment du sinistre)
- **Solution production** : Mettre en place des alertes si une sauvegarde Ã©choue ou dÃ©passe un dÃ©lai tolÃ©rance crÃ©er des dashboards grafana pour le monitoring efficace.

**5. Pas de test rÃ©gulier de restauration**
- **ProblÃ¨me** : On suppose que les restaurations fonctionnent, mais aucun test n'est effectuÃ©
- **Risque** : DÃ©couvrir lors d'un sinistre rÃ©el que les backups sont corrompus ou inutilisables
- **Solution production** : Avoir un **plan de test regulier** (Disaster Recovery Drills) pour valider les procÃ©dures

**6. RTO et RPO trop Ã©levÃ©s pour certains mÃ©tiers**
- **ProblÃ¨me** : Un RTO de 5-10 min et RPO de 1 min ne conviennent pas aux applications critiques
- **Risque** : Moins acceptable selon la criticitÃ© du service
- **Solution production** : Mettre en place une **rÃ©plication active-active** ou une **haute disponibilitÃ©** pour rÃ©duire RTO/RPO

**7. Pas de gestion d'audit ni de conformitÃ©**
- **ProblÃ¨me** : Aucune trace de qui a accÃ©dÃ©, modifiÃ© ou restaurÃ© les donnÃ©es
- **Risque** : Non-conformitÃ© aux standards d'audit et de gouvernance
- **Solution production** : ImplÃ©menter des logs d'audit, du versioning des backups, et de la traÃ§abilitÃ©

  
**Exercice 5 :**  
Proposez une architecture plus robuste.   
  
**RÃ©ponse :**  

Voici une architecture PRA/PCA **production-ready** qui adresse les limitations de la solution actuelle :


```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STOCKAGE EXTERNALISÃ‰ MULTI-RÃ‰GION                       â”‚
â”‚                                                                      â”‚
â”‚  AWS S3 / Google Cloud Storage / Azure Blob Storage                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Backup Bucket (Versioned + Encrypted + Immutable)             â”‚ â”‚
â”‚  â”‚  . Retention: 90 jours                                         â”‚ â”‚
â”‚  â”‚  . Encryption: AES-256 (KMS)                                   â”‚ â”‚
â”‚  â”‚  . Replication: Cross-region (gÃ©ographique)                   â”‚ â”‚
â”‚  â”‚  . Backup chiffrÃ© toutes les minutes                           â”‚ â”‚
â”‚  â”‚  . Snapshots: Horaires + Quotidiens + Hebdomadaires           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaractÃ©ristiques clÃ©s de cette architecture robuste :**

**1. Haute DisponibilitÃ© Multi-RÃ©gion (Active-Active)**
- Deux clusters Kubernetes dans **diffÃ©rentes rÃ©gions gÃ©ographiques** (Europe + US)
- Application **rÃ©pliquÃ©e et distribuÃ©e** sur les deux rÃ©gions
- RequÃªtes routÃ©es via **DNS load balancing** (Route 53, Cloud DNS) ou **Anycast IP**
- Avantages :
  - Pas de point unique de dÃ©faillance
  - RÃ©silience aux catastrophes rÃ©gionales
  - Latence rÃ©duite pour les utilisateurs proches
  - ContinuitÃ© de service mÃªme en cas d'outage rÃ©gional complet

**2. RÃ©plication de DonnÃ©es Bidirectionnelle**
- DonnÃ©es synchronisÃ©es en temps rÃ©el entre les deux clusters
- Technologies possibles : Ceph, Rook, DRBD, ou outils cloud (AWS DMS, GCP Datastream)
- RPO quasi-nul (perte max quelques secondes)
- Permet lecture/write sur les deux cÃ´tÃ©s (gÃ©o-rÃ©partition)

**4. SÃ©curitÃ© et ConformitÃ©**
- **Chiffrement en transit** : TLS 1.3 pour toutes les communications
- **Chiffrement au repos** : AES-256 pour donnÃ©es et backups (gestion clÃ©s via KMS)
- **ImmuabilitÃ©** : Mode WORM (Write Once Read Many) sur les backups pour Ã©viter la suppression accidentelle

**5. Monitoring et ObservabilitÃ©**
- **Prometheus** pour les mÃ©triques Kubernetes
- **Grafana** pour la visualisation des dashboards (statut backups, rÃ©plication, RTO/RPO)
- **Alertes** : PagerDuty si backup Ã©choue ou rÃ©plication retardÃ©e
- **Traces distribuÃ©es** : Jaeger pour tracer les opÃ©rations critiques
- **Logs centralisÃ©s** : Elasticsearch/Loki pour rechercher rapidement les erreurs

**6. Tests RÃ©guliers des backups**
- Restauration mensuelle d'un backup Ã  vide (test environnement)
- Validation temps de restauration = RTO mesurÃ©
- Documentation de procÃ©dures et runbooks
- Plan de communication d'urgence

**7. RTO et RPO OptimisÃ©s**
- **RPO** : â‰¤1 minute (sauvegardes Cloud toutes les minutes)
- **RTO** : â‰¤5 minutes (basculement automatique via load balancer)
- PossibilitÃ© de rÃ©duire Ã  **RPO <30sec** et **RTO <1min** avec rÃ©plication synchrone


---------------------------------------------------
SÃ©quence 6 : Ateliers  
DifficultÃ© : Moyenne (~2 heures)
---------------------------------------------------
### **Atelier 1 : Ajoutez une fonctionnalitÃ© Ã  votre application**  
**Ajouter une route GET /status** dans votre application qui affiche en JSON :
* count : nombre dâ€™Ã©vÃ©nements en base
* last_backup_file : nom du dernier backup prÃ©sent dans /backup
* backup_age_seconds : Ã¢ge du dernier backup

![alt text](image.png)

---------------------------------------------------
### **Atelier 2 : Choisir notre point de restauration**  
Aujourdâ€™hui nous restaurobs â€œle dernier backupâ€. Nous souhaitons **ajouter la capacitÃ© de choisir un point de restauration**.

**ProcÃ©dure de restauration (runbook) :**
1. **Lister les backups disponibles**
   - Ouvrir un shell dans un pod ou utiliser `kubectl -n pra run debug-backup` comme dÃ©crit plus haut.
   - ExÃ©cuter `ls -1 /backup | sort` pour voir tous les fichiers `app-<timestamp>.db` rangÃ©s par ordre chronologique.
   - Notez le nom du fichier correspondant au point de restauration dÃ©sirÃ© (par exemple `app-1772098321.db`).

2. **Suspendre le cron de sauvegarde** afin d'Ã©viter qu'un job ne copie une nouvelle version pendant la restauration :
   ```bash
   kubectl -n pra patch cronjob sqlite-backup -p '{"spec":{"suspend":true}}'
   ```

3. **ArrÃªter l'application** (optionnel mais recommandÃ©) :
   ```bash
   kubectl -n pra scale deployment flask --replicas=0
   ```
   Cela garantit qu'aucune Ã©criture n'aura lieu pendant l'opÃ©ration.

4. **PrÃ©parer le volume de donnÃ©es**
   - Si le PVC `pra-data` existe dÃ©jÃ  (vide ou non), vous pouvez le supprimer et le recrÃ©er en appliquant les manifests :
     ```bash
     kubectl -n pra delete pvc pra-data
     kubectl apply -f k8s/11-pvc-data.yaml
     kubectl apply -f k8s/20-deployment.yaml  # pour recrÃ©er le pod si nÃ©cessaire
     ```
   - Alternativement, vous pouvez monter le PVC dans un pod de debug et purger manuellement `/data/app.db`.

5. **Copier le backup choisi dans le PVC de donnÃ©es**
   - CrÃ©er un job de restauration adâ€‘hoc en remplaÃ§ant la variable dans `pra/50-job-restore.yaml` ou en lanÃ§ant la commande manuelle :
     ```bash
     kubectl -n pra run restore-chosen --restart=Never --rm -it --image=alpine -- sh -c \
       "cp /backup/app-1772098321.db /data/app.db" \
       -v pra-data:/data -v pra-backup:/backup
     ```
     (adaptez le nom du fichier selon votre sÃ©lection)
   - Si vous prÃ©fÃ©rez modifier `pra/50-job-restore.yaml`, mettez le nom dans la ligne `LATEST=$(ls -t /backup/*.db | head -1)` et remplacez la logique par `cp /backup/app-1772098321.db /data/app.db`.

6. **VÃ©rifier la restauration**
   - Relancer l'application si elle a Ã©tÃ© arrÃªtÃ©e :
     ```bash
     kubectl -n pra scale deployment flask --replicas=1
     ```
   - Attendre que le pod soit prÃªt (`kubectl -n pra get pods`).
   - Tester avec `/count` et `/consultation` pour s'assurer que les donnÃ©es correspondent au point de restauration choisi.

7. **RedÃ©marrer le cron de sauvegarde** :
   ```bash
   kubectl -n pra patch cronjob sqlite-backup -p '{"spec":{"suspend":false}}'
   ```

8. **(Optionnel) VÃ©rifier le backup actuel** pour confirmer que la prochaine sauvegarde s'exÃ©cute correctement et qu'elle reprend Ã  partir de la base restaurÃ©e.

> ğŸ’¡ *Conseil* : conservez un log de la restauration (date, nom du fichier, raison) pour l'audit et la traÃ§abilitÃ©.

Cette procÃ©dure donne la souplesse de choisir nâ€™importe quel point dans le temps et sâ€™applique dans tous les environnements oÃ¹ les backups sont accessibles.  
  
---------------------------------------------------
Evaluation
---------------------------------------------------
Cet atelier PRA PCA, **notÃ© sur 20 points**, est Ã©valuÃ© sur la base du barÃ¨me suivant :  
- SÃ©rie d'exerices (5 points)
- Atelier NÂ°1 - Ajout d'un fonctionnalitÃ© (4 points)
- Atelier NÂ°2 - Choisir son point de restauration (4 points)
- QualitÃ© du Readme (lisibilitÃ©, erreur, ...) (3 points)
- Processus travail (quantitÃ© de commits, cohÃ©rence globale, interventions externes, ...) (4 points) 

